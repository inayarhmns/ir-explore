{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN1D for text classification.\n",
    "\n",
    "Inaya Rahmanisa\n",
    "\n",
    "\n",
    "References:\n",
    "- Tutorial Conv1D and LSTM from scratch by Pak Alfan Farizki Wicaksono, Fasilkom UI\n",
    "- https://cezannec.github.io/CNN_Text_Classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self, sequence_length, documents, labels,\n",
    "    ):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.words = self.load_words(documents)\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        # id vocab mulai dari 1, bukan 0; 0 untuk [PAD]\n",
    "        # di-pad supaya length doc-nya sama semua\n",
    "        self.index_to_word = {(index + 1): word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: (index + 1) for index, word in enumerate(self.uniq_words)}\n",
    "        self.index_to_word[0] = \"[PAD]\"\n",
    "        self.word_to_index[\"[PAD]\"] = 0\n",
    "\n",
    "        self.labels = labels\n",
    "        self.docs = []\n",
    "        for doc in documents:\n",
    "            self.docs.append(self.to_ids(doc))\n",
    "\n",
    "    def to_ids(self, doc):\n",
    "        doc = [self.word_to_index[w] for w in self.tokenize(doc)]\n",
    "        if len(doc) >= self.sequence_length:\n",
    "            doc = doc[:self.sequence_length]\n",
    "        else:\n",
    "            doc += [0] * (self.sequence_length - len(doc))\n",
    "        return doc\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        return text.split(' ')\n",
    "\n",
    "    def load_words(self, documents):\n",
    "        text = \"\"\n",
    "        for doc in documents:\n",
    "          text += doc + \" \"\n",
    "        return self.tokenize(text)\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.docs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.docs[index]),\n",
    "            torch.tensor(self.labels[index]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super().__init__()\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.W = nn.Parameter(torch.Tensor(self.n_inputs, self.n_outputs))\n",
    "        self.init_weights()\n",
    "    def init_weights(self):\n",
    "        for param in self.parameters():\n",
    "            nn.init.uniform_(param, -0.1, 0.1)\n",
    "    def forward(self, x):\n",
    "        return x @ self.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_width):\n",
    "        \"\"\" kernel_width harus ganjil \"\"\"\n",
    "        super(Conv1D, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_width = kernel_width\n",
    "        self.pad_size = (self.kernel_width - 1) // 2\n",
    "        self.kernel = Linear(kernel_width * in_channels, out_channels) # ini yg menentukan size keluaran outputnya (karena size W tergantung sama output size)\n",
    "    def forward(self, x):\n",
    "        # padding untuk convolution\n",
    "        x = nn.functional.pad(x, (self.pad_size, self.pad_size), \"constant\", 0)\n",
    "        \n",
    "        l = []\n",
    "        # dilakukan sebanyak shape[2] - k + 1\n",
    "        for i in range(self.pad_size, x.shape[2] - self.pad_size): # shape[2] ini shape dimensi paling dalam, contoh tadinya 5 setelah dipad jadi 7\n",
    "            patch = x[:, :, i - self.pad_size: i + self.pad_size + 1] # kalau ini sliding patch nya dari awal (0) sampai kernel_width (3)\n",
    "            # print(patch)\n",
    "            patch = patch.reshape(x.shape[0], self.in_channels * self.kernel_width) # gabung (flatten patch) jadi ukurannya in_channel*kernel_width. x.shape[0] itu channel size, banyaknya matrix yang sama2 ukuran in_channel*kernel_width\n",
    "            # print(patch)\n",
    "            l.append(self.kernel(patch))\n",
    "           \n",
    "            \n",
    "        return torch.stack(l, dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNet(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, input_channel, embedding_dim, hidden_dim, output_dim):\n",
    "\n",
    "        super(CNNNet,self).__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        # padding_idx (int, optional) – If specified, the entries at padding_idx do\n",
    "        # not contribute to the gradient; therefore, the embedding vector at\n",
    "        # padding_idx is not updated during training, i.e. it remains as a fixed “pad”.\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        # CNN layer process the vector sequences\n",
    "        self.cnn = Conv1D(input_channel, output_dim, 3)\n",
    "\n",
    "        # Dense layer to predict\n",
    "        self.fc = nn.Linear(hidden_dim, 1) # ouput_dim is 1 for text classification\n",
    "\n",
    "        # Prediction activation function\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "\n",
    "        \n",
    "        output = self.cnn(embedded)\n",
    "        output = torch.mean(output, dim=1) #mean pooling\n",
    "        # output = torch.max(output, dim=1) #max pooling as used by cezannec ref\n",
    "        # print(f\"output shape after mean {output.shape}\")\n",
    "        output = self.fc(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, model, batch_size, max_epochs):\n",
    "    model.train()\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    print(len(dataset.index_to_word))\n",
    "    for epoch in range(max_epochs):\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            \n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'dan', 2: 'rapih', 3: 'kotor', 4: 'buku', 5: 'bagus', 6: 'cerdas', 7: 'menarik', 8: 'rumah', 9: 'cantik', 10: 'bersih', 11: 'hotel', 12: 'berisik', 13: 'bau', 14: 'kantin', 15: 'jorok', 16: 'mahal', 17: 'panas', 18: '', 0: '[PAD]'}\n",
      "19\n",
      "{'epoch': 0, 'batch': 0, 'loss': 0.6965881586074829}\n",
      "{'epoch': 0, 'batch': 1, 'loss': 0.6845444440841675}\n",
      "{'epoch': 1, 'batch': 0, 'loss': 0.6910114288330078}\n",
      "{'epoch': 1, 'batch': 1, 'loss': 0.6828407049179077}\n",
      "{'epoch': 2, 'batch': 0, 'loss': 0.6869640350341797}\n",
      "{'epoch': 2, 'batch': 1, 'loss': 0.6808914542198181}\n",
      "{'epoch': 3, 'batch': 0, 'loss': 0.6832168698310852}\n",
      "{'epoch': 3, 'batch': 1, 'loss': 0.6788530349731445}\n",
      "{'epoch': 4, 'batch': 0, 'loss': 0.6795915365219116}\n",
      "{'epoch': 4, 'batch': 1, 'loss': 0.6767730712890625}\n",
      "{'epoch': 5, 'batch': 0, 'loss': 0.6760233640670776}\n",
      "{'epoch': 5, 'batch': 1, 'loss': 0.6746698617935181}\n",
      "{'epoch': 6, 'batch': 0, 'loss': 0.6724791526794434}\n",
      "{'epoch': 6, 'batch': 1, 'loss': 0.6725500822067261}\n",
      "{'epoch': 7, 'batch': 0, 'loss': 0.6689388751983643}\n",
      "{'epoch': 7, 'batch': 1, 'loss': 0.6704152822494507}\n",
      "{'epoch': 8, 'batch': 0, 'loss': 0.6653881072998047}\n",
      "{'epoch': 8, 'batch': 1, 'loss': 0.6682630777359009}\n",
      "{'epoch': 9, 'batch': 0, 'loss': 0.6618152260780334}\n",
      "{'epoch': 9, 'batch': 1, 'loss': 0.6660895347595215}\n",
      "{'epoch': 10, 'batch': 0, 'loss': 0.6582103967666626}\n",
      "{'epoch': 10, 'batch': 1, 'loss': 0.6638889312744141}\n",
      "{'epoch': 11, 'batch': 0, 'loss': 0.6545644998550415}\n",
      "{'epoch': 11, 'batch': 1, 'loss': 0.6616548895835876}\n",
      "{'epoch': 12, 'batch': 0, 'loss': 0.6508691310882568}\n",
      "{'epoch': 12, 'batch': 1, 'loss': 0.6593805551528931}\n",
      "{'epoch': 13, 'batch': 0, 'loss': 0.6471161842346191}\n",
      "{'epoch': 13, 'batch': 1, 'loss': 0.6570586562156677}\n",
      "{'epoch': 14, 'batch': 0, 'loss': 0.6432982683181763}\n",
      "{'epoch': 14, 'batch': 1, 'loss': 0.6546823382377625}\n",
      "{'epoch': 15, 'batch': 0, 'loss': 0.6394079923629761}\n",
      "{'epoch': 15, 'batch': 1, 'loss': 0.6522440910339355}\n",
      "{'epoch': 16, 'batch': 0, 'loss': 0.6354389190673828}\n",
      "{'epoch': 16, 'batch': 1, 'loss': 0.6497371792793274}\n",
      "{'epoch': 17, 'batch': 0, 'loss': 0.6313847899436951}\n",
      "{'epoch': 17, 'batch': 1, 'loss': 0.6471543908119202}\n",
      "{'epoch': 18, 'batch': 0, 'loss': 0.6272398233413696}\n",
      "{'epoch': 18, 'batch': 1, 'loss': 0.6444889903068542}\n",
      "{'epoch': 19, 'batch': 0, 'loss': 0.6229987740516663}\n",
      "{'epoch': 19, 'batch': 1, 'loss': 0.6417341828346252}\n",
      "{'epoch': 20, 'batch': 0, 'loss': 0.6186568737030029}\n",
      "{'epoch': 20, 'batch': 1, 'loss': 0.6388834118843079}\n",
      "{'epoch': 21, 'batch': 0, 'loss': 0.6142094731330872}\n",
      "{'epoch': 21, 'batch': 1, 'loss': 0.6359302997589111}\n",
      "{'epoch': 22, 'batch': 0, 'loss': 0.6096526384353638}\n",
      "{'epoch': 22, 'batch': 1, 'loss': 0.6328688859939575}\n",
      "{'epoch': 23, 'batch': 0, 'loss': 0.6049822568893433}\n",
      "{'epoch': 23, 'batch': 1, 'loss': 0.6296929717063904}\n",
      "{'epoch': 24, 'batch': 0, 'loss': 0.600195050239563}\n",
      "{'epoch': 24, 'batch': 1, 'loss': 0.626396894454956}\n",
      "{'epoch': 25, 'batch': 0, 'loss': 0.5952877998352051}\n",
      "{'epoch': 25, 'batch': 1, 'loss': 0.6229749917984009}\n",
      "{'epoch': 26, 'batch': 0, 'loss': 0.5902575254440308}\n",
      "{'epoch': 26, 'batch': 1, 'loss': 0.6194221377372742}\n",
      "{'epoch': 27, 'batch': 0, 'loss': 0.5851013660430908}\n",
      "{'epoch': 27, 'batch': 1, 'loss': 0.6157331466674805}\n",
      "{'epoch': 28, 'batch': 0, 'loss': 0.5798169374465942}\n",
      "{'epoch': 28, 'batch': 1, 'loss': 0.6119034290313721}\n",
      "{'epoch': 29, 'batch': 0, 'loss': 0.5744024515151978}\n",
      "{'epoch': 29, 'batch': 1, 'loss': 0.6079282760620117}\n",
      "{'epoch': 30, 'batch': 0, 'loss': 0.5688559412956238}\n",
      "{'epoch': 30, 'batch': 1, 'loss': 0.6038036346435547}\n",
      "{'epoch': 31, 'batch': 0, 'loss': 0.5631758570671082}\n",
      "{'epoch': 31, 'batch': 1, 'loss': 0.5995258092880249}\n",
      "{'epoch': 32, 'batch': 0, 'loss': 0.5573611855506897}\n",
      "{'epoch': 32, 'batch': 1, 'loss': 0.5950911045074463}\n",
      "{'epoch': 33, 'batch': 0, 'loss': 0.5514111518859863}\n",
      "{'epoch': 33, 'batch': 1, 'loss': 0.5904965400695801}\n",
      "{'epoch': 34, 'batch': 0, 'loss': 0.5453253984451294}\n",
      "{'epoch': 34, 'batch': 1, 'loss': 0.5857393741607666}\n",
      "{'epoch': 35, 'batch': 0, 'loss': 0.5391038656234741}\n",
      "{'epoch': 35, 'batch': 1, 'loss': 0.5808172225952148}\n",
      "{'epoch': 36, 'batch': 0, 'loss': 0.5327469110488892}\n",
      "{'epoch': 36, 'batch': 1, 'loss': 0.5757281184196472}\n",
      "{'epoch': 37, 'batch': 0, 'loss': 0.5262556672096252}\n",
      "{'epoch': 37, 'batch': 1, 'loss': 0.5704706907272339}\n",
      "{'epoch': 38, 'batch': 0, 'loss': 0.519631028175354}\n",
      "{'epoch': 38, 'batch': 1, 'loss': 0.5650436878204346}\n",
      "{'epoch': 39, 'batch': 0, 'loss': 0.5128747224807739}\n",
      "{'epoch': 39, 'batch': 1, 'loss': 0.5594465136528015}\n",
      "{'epoch': 40, 'batch': 0, 'loss': 0.5059891939163208}\n",
      "{'epoch': 40, 'batch': 1, 'loss': 0.5536792278289795}\n",
      "{'epoch': 41, 'batch': 0, 'loss': 0.4989766478538513}\n",
      "{'epoch': 41, 'batch': 1, 'loss': 0.5477418899536133}\n",
      "{'epoch': 42, 'batch': 0, 'loss': 0.4918404519557953}\n",
      "{'epoch': 42, 'batch': 1, 'loss': 0.5416356921195984}\n",
      "{'epoch': 43, 'batch': 0, 'loss': 0.4845842123031616}\n",
      "{'epoch': 43, 'batch': 1, 'loss': 0.5353618264198303}\n",
      "{'epoch': 44, 'batch': 0, 'loss': 0.4772118031978607}\n",
      "{'epoch': 44, 'batch': 1, 'loss': 0.5289223194122314}\n",
      "{'epoch': 45, 'batch': 0, 'loss': 0.46972787380218506}\n",
      "{'epoch': 45, 'batch': 1, 'loss': 0.5223197340965271}\n",
      "{'epoch': 46, 'batch': 0, 'loss': 0.46213746070861816}\n",
      "{'epoch': 46, 'batch': 1, 'loss': 0.5155569911003113}\n",
      "{'epoch': 47, 'batch': 0, 'loss': 0.45444607734680176}\n",
      "{'epoch': 47, 'batch': 1, 'loss': 0.5086379051208496}\n",
      "{'epoch': 48, 'batch': 0, 'loss': 0.44665953516960144}\n",
      "{'epoch': 48, 'batch': 1, 'loss': 0.5015664100646973}\n",
      "{'epoch': 49, 'batch': 0, 'loss': 0.4387844502925873}\n",
      "{'epoch': 49, 'batch': 1, 'loss': 0.49434763193130493}\n",
      "{'epoch': 50, 'batch': 0, 'loss': 0.43082761764526367}\n",
      "{'epoch': 50, 'batch': 1, 'loss': 0.48698675632476807}\n",
      "{'epoch': 51, 'batch': 0, 'loss': 0.422796368598938}\n",
      "{'epoch': 51, 'batch': 1, 'loss': 0.47948968410491943}\n",
      "{'epoch': 52, 'batch': 0, 'loss': 0.4146983325481415}\n",
      "{'epoch': 52, 'batch': 1, 'loss': 0.47186312079429626}\n",
      "{'epoch': 53, 'batch': 0, 'loss': 0.40654149651527405}\n",
      "{'epoch': 53, 'batch': 1, 'loss': 0.46411389112472534}\n",
      "{'epoch': 54, 'batch': 0, 'loss': 0.39833444356918335}\n",
      "{'epoch': 54, 'batch': 1, 'loss': 0.4562497138977051}\n",
      "{'epoch': 55, 'batch': 0, 'loss': 0.3900858163833618}\n",
      "{'epoch': 55, 'batch': 1, 'loss': 0.44827860593795776}\n",
      "{'epoch': 56, 'batch': 0, 'loss': 0.38180458545684814}\n",
      "{'epoch': 56, 'batch': 1, 'loss': 0.44020920991897583}\n",
      "{'epoch': 57, 'batch': 0, 'loss': 0.3734999895095825}\n",
      "{'epoch': 57, 'batch': 1, 'loss': 0.43205052614212036}\n",
      "{'epoch': 58, 'batch': 0, 'loss': 0.36518165469169617}\n",
      "{'epoch': 58, 'batch': 1, 'loss': 0.42381200194358826}\n",
      "{'epoch': 59, 'batch': 0, 'loss': 0.3568589985370636}\n",
      "{'epoch': 59, 'batch': 1, 'loss': 0.4155035614967346}\n",
      "{'epoch': 60, 'batch': 0, 'loss': 0.34854185581207275}\n",
      "{'epoch': 60, 'batch': 1, 'loss': 0.4071354269981384}\n",
      "{'epoch': 61, 'batch': 0, 'loss': 0.3402400612831116}\n",
      "{'epoch': 61, 'batch': 1, 'loss': 0.39871805906295776}\n",
      "{'epoch': 62, 'batch': 0, 'loss': 0.33196353912353516}\n",
      "{'epoch': 62, 'batch': 1, 'loss': 0.39026230573654175}\n",
      "{'epoch': 63, 'batch': 0, 'loss': 0.3237220048904419}\n",
      "{'epoch': 63, 'batch': 1, 'loss': 0.3817790746688843}\n",
      "{'epoch': 64, 'batch': 0, 'loss': 0.3155251741409302}\n",
      "{'epoch': 64, 'batch': 1, 'loss': 0.37327951192855835}\n",
      "{'epoch': 65, 'batch': 0, 'loss': 0.3073827624320984}\n",
      "{'epoch': 65, 'batch': 1, 'loss': 0.3647748827934265}\n",
      "{'epoch': 66, 'batch': 0, 'loss': 0.29930412769317627}\n",
      "{'epoch': 66, 'batch': 1, 'loss': 0.35627639293670654}\n",
      "{'epoch': 67, 'batch': 0, 'loss': 0.29129868745803833}\n",
      "{'epoch': 67, 'batch': 1, 'loss': 0.347795307636261}\n",
      "{'epoch': 68, 'batch': 0, 'loss': 0.283375084400177}\n",
      "{'epoch': 68, 'batch': 1, 'loss': 0.33934280276298523}\n",
      "{'epoch': 69, 'batch': 0, 'loss': 0.27554208040237427}\n",
      "{'epoch': 69, 'batch': 1, 'loss': 0.33092987537384033}\n",
      "{'epoch': 70, 'batch': 0, 'loss': 0.26780813932418823}\n",
      "{'epoch': 70, 'batch': 1, 'loss': 0.3225673735141754}\n",
      "{'epoch': 71, 'batch': 0, 'loss': 0.260180801153183}\n",
      "{'epoch': 71, 'batch': 1, 'loss': 0.3142658472061157}\n",
      "{'epoch': 72, 'batch': 0, 'loss': 0.2526676654815674}\n",
      "{'epoch': 72, 'batch': 1, 'loss': 0.306035578250885}\n",
      "{'epoch': 73, 'batch': 0, 'loss': 0.24527567625045776}\n",
      "{'epoch': 73, 'batch': 1, 'loss': 0.29788634181022644}\n",
      "{'epoch': 74, 'batch': 0, 'loss': 0.23801128566265106}\n",
      "{'epoch': 74, 'batch': 1, 'loss': 0.289827823638916}\n",
      "{'epoch': 75, 'batch': 0, 'loss': 0.23088037967681885}\n",
      "{'epoch': 75, 'batch': 1, 'loss': 0.2818688750267029}\n",
      "{'epoch': 76, 'batch': 0, 'loss': 0.2238883674144745}\n",
      "{'epoch': 76, 'batch': 1, 'loss': 0.27401816844940186}\n",
      "{'epoch': 77, 'batch': 0, 'loss': 0.2170400619506836}\n",
      "{'epoch': 77, 'batch': 1, 'loss': 0.26628363132476807}\n",
      "{'epoch': 78, 'batch': 0, 'loss': 0.21033981442451477}\n",
      "{'epoch': 78, 'batch': 1, 'loss': 0.2586727738380432}\n",
      "{'epoch': 79, 'batch': 0, 'loss': 0.20379121601581573}\n",
      "{'epoch': 79, 'batch': 1, 'loss': 0.2511923313140869}\n",
      "{'epoch': 80, 'batch': 0, 'loss': 0.1973973661661148}\n",
      "{'epoch': 80, 'batch': 1, 'loss': 0.24384859204292297}\n",
      "{'epoch': 81, 'batch': 0, 'loss': 0.19116081297397614}\n",
      "{'epoch': 81, 'batch': 1, 'loss': 0.23664727807044983}\n",
      "{'epoch': 82, 'batch': 0, 'loss': 0.18508362770080566}\n",
      "{'epoch': 82, 'batch': 1, 'loss': 0.22959330677986145}\n",
      "{'epoch': 83, 'batch': 0, 'loss': 0.17916730046272278}\n",
      "{'epoch': 83, 'batch': 1, 'loss': 0.22269108891487122}\n",
      "{'epoch': 84, 'batch': 0, 'loss': 0.17341269552707672}\n",
      "{'epoch': 84, 'batch': 1, 'loss': 0.21594437956809998}\n",
      "{'epoch': 85, 'batch': 0, 'loss': 0.16782012581825256}\n",
      "{'epoch': 85, 'batch': 1, 'loss': 0.20935624837875366}\n",
      "{'epoch': 86, 'batch': 0, 'loss': 0.16238966584205627}\n",
      "{'epoch': 86, 'batch': 1, 'loss': 0.20292925834655762}\n",
      "{'epoch': 87, 'batch': 0, 'loss': 0.1571207344532013}\n",
      "{'epoch': 87, 'batch': 1, 'loss': 0.19666525721549988}\n",
      "{'epoch': 88, 'batch': 0, 'loss': 0.15201237797737122}\n",
      "{'epoch': 88, 'batch': 1, 'loss': 0.19056566059589386}\n",
      "{'epoch': 89, 'batch': 0, 'loss': 0.14706334471702576}\n",
      "{'epoch': 89, 'batch': 1, 'loss': 0.18463124334812164}\n",
      "{'epoch': 90, 'batch': 0, 'loss': 0.14227184653282166}\n",
      "{'epoch': 90, 'batch': 1, 'loss': 0.17886227369308472}\n",
      "{'epoch': 91, 'batch': 0, 'loss': 0.13763582706451416}\n",
      "{'epoch': 91, 'batch': 1, 'loss': 0.17325852811336517}\n",
      "{'epoch': 92, 'batch': 0, 'loss': 0.13315296173095703}\n",
      "{'epoch': 92, 'batch': 1, 'loss': 0.1678193211555481}\n",
      "{'epoch': 93, 'batch': 0, 'loss': 0.12882059812545776}\n",
      "{'epoch': 93, 'batch': 1, 'loss': 0.16254356503486633}\n",
      "{'epoch': 94, 'batch': 0, 'loss': 0.12463594973087311}\n",
      "{'epoch': 94, 'batch': 1, 'loss': 0.15742971003055573}\n",
      "{'epoch': 95, 'batch': 0, 'loss': 0.12059579789638519}\n",
      "{'epoch': 95, 'batch': 1, 'loss': 0.1524759829044342}\n",
      "{'epoch': 96, 'batch': 0, 'loss': 0.1166970506310463}\n",
      "{'epoch': 96, 'batch': 1, 'loss': 0.14768002927303314}\n",
      "{'epoch': 97, 'batch': 0, 'loss': 0.11293622851371765}\n",
      "{'epoch': 97, 'batch': 1, 'loss': 0.14303946495056152}\n",
      "{'epoch': 98, 'batch': 0, 'loss': 0.10930977761745453}\n",
      "{'epoch': 98, 'batch': 1, 'loss': 0.1385515332221985}\n",
      "{'epoch': 99, 'batch': 0, 'loss': 0.10581415891647339}\n",
      "{'epoch': 99, 'batch': 1, 'loss': 0.13421323895454407}\n",
      "{'epoch': 100, 'batch': 0, 'loss': 0.10244554281234741}\n",
      "{'epoch': 100, 'batch': 1, 'loss': 0.13002139329910278}\n",
      "{'epoch': 101, 'batch': 0, 'loss': 0.09920021891593933}\n",
      "{'epoch': 101, 'batch': 1, 'loss': 0.1259726583957672}\n",
      "{'epoch': 102, 'batch': 0, 'loss': 0.09607449173927307}\n",
      "{'epoch': 102, 'batch': 1, 'loss': 0.122063547372818}\n",
      "{'epoch': 103, 'batch': 0, 'loss': 0.09306450933218002}\n",
      "{'epoch': 103, 'batch': 1, 'loss': 0.1182904839515686}\n",
      "{'epoch': 104, 'batch': 0, 'loss': 0.09016640484333038}\n",
      "{'epoch': 104, 'batch': 1, 'loss': 0.11464978754520416}\n",
      "{'epoch': 105, 'batch': 0, 'loss': 0.08737649023532867}\n",
      "{'epoch': 105, 'batch': 1, 'loss': 0.11113769561052322}\n",
      "{'epoch': 106, 'batch': 0, 'loss': 0.08469107747077942}\n",
      "{'epoch': 106, 'batch': 1, 'loss': 0.10775043070316315}\n",
      "{'epoch': 107, 'batch': 0, 'loss': 0.0821063369512558}\n",
      "{'epoch': 107, 'batch': 1, 'loss': 0.10448423027992249}\n",
      "{'epoch': 108, 'batch': 0, 'loss': 0.07961864769458771}\n",
      "{'epoch': 108, 'batch': 1, 'loss': 0.10133522748947144}\n",
      "{'epoch': 109, 'batch': 0, 'loss': 0.07722452282905579}\n",
      "{'epoch': 109, 'batch': 1, 'loss': 0.09829966723918915}\n",
      "{'epoch': 110, 'batch': 0, 'loss': 0.07492051273584366}\n",
      "{'epoch': 110, 'batch': 1, 'loss': 0.09537378698587418}\n",
      "{'epoch': 111, 'batch': 0, 'loss': 0.07270301133394241}\n",
      "{'epoch': 111, 'batch': 1, 'loss': 0.09255383163690567}\n",
      "{'epoch': 112, 'batch': 0, 'loss': 0.07056886702775955}\n",
      "{'epoch': 112, 'batch': 1, 'loss': 0.08983610570430756}\n",
      "{'epoch': 113, 'batch': 0, 'loss': 0.06851473450660706}\n",
      "{'epoch': 113, 'batch': 1, 'loss': 0.08721704035997391}\n",
      "{'epoch': 114, 'batch': 0, 'loss': 0.06653754413127899}\n",
      "{'epoch': 114, 'batch': 1, 'loss': 0.08469302207231522}\n",
      "{'epoch': 115, 'batch': 0, 'loss': 0.06463408470153809}\n",
      "{'epoch': 115, 'batch': 1, 'loss': 0.08226065337657928}\n",
      "{'epoch': 116, 'batch': 0, 'loss': 0.06280158460140228}\n",
      "{'epoch': 116, 'batch': 1, 'loss': 0.07991652190685272}\n",
      "{'epoch': 117, 'batch': 0, 'loss': 0.0610370934009552}\n",
      "{'epoch': 117, 'batch': 1, 'loss': 0.07765726745128632}\n",
      "{'epoch': 118, 'batch': 0, 'loss': 0.05933784693479538}\n",
      "{'epoch': 118, 'batch': 1, 'loss': 0.07547973841428757}\n",
      "{'epoch': 119, 'batch': 0, 'loss': 0.05770127475261688}\n",
      "{'epoch': 119, 'batch': 1, 'loss': 0.07338075339794159}\n",
      "{'epoch': 120, 'batch': 0, 'loss': 0.0561247393488884}\n",
      "{'epoch': 120, 'batch': 1, 'loss': 0.07135732471942902}\n",
      "{'epoch': 121, 'batch': 0, 'loss': 0.054605692625045776}\n",
      "{'epoch': 121, 'batch': 1, 'loss': 0.06940649449825287}\n",
      "{'epoch': 122, 'batch': 0, 'loss': 0.053141891956329346}\n",
      "{'epoch': 122, 'batch': 1, 'loss': 0.0675254613161087}\n",
      "{'epoch': 123, 'batch': 0, 'loss': 0.05173102766275406}\n",
      "{'epoch': 123, 'batch': 1, 'loss': 0.06571140885353088}\n",
      "{'epoch': 124, 'batch': 0, 'loss': 0.05037086829543114}\n",
      "{'epoch': 124, 'batch': 1, 'loss': 0.06396173685789108}\n",
      "{'epoch': 125, 'batch': 0, 'loss': 0.04905933141708374}\n",
      "{'epoch': 125, 'batch': 1, 'loss': 0.06227388232946396}\n",
      "{'epoch': 126, 'batch': 0, 'loss': 0.047794412821531296}\n",
      "{'epoch': 126, 'batch': 1, 'loss': 0.060645394027233124}\n",
      "{'epoch': 127, 'batch': 0, 'loss': 0.0465741902589798}\n",
      "{'epoch': 127, 'batch': 1, 'loss': 0.05907392129302025}\n",
      "{'epoch': 128, 'batch': 0, 'loss': 0.04539678245782852}\n",
      "{'epoch': 128, 'batch': 1, 'loss': 0.057557154446840286}\n",
      "{'epoch': 129, 'batch': 0, 'loss': 0.044260427355766296}\n",
      "{'epoch': 129, 'batch': 1, 'loss': 0.05609293282032013}\n",
      "{'epoch': 130, 'batch': 0, 'loss': 0.043163448572158813}\n",
      "{'epoch': 130, 'batch': 1, 'loss': 0.054679155349731445}\n",
      "{'epoch': 131, 'batch': 0, 'loss': 0.04210419952869415}\n",
      "{'epoch': 131, 'batch': 1, 'loss': 0.05331379175186157}\n",
      "{'epoch': 132, 'batch': 0, 'loss': 0.04108113795518875}\n",
      "{'epoch': 132, 'batch': 1, 'loss': 0.05199490487575531}\n",
      "{'epoch': 133, 'batch': 0, 'loss': 0.04009281098842621}\n",
      "{'epoch': 133, 'batch': 1, 'loss': 0.05072065070271492}\n",
      "{'epoch': 134, 'batch': 0, 'loss': 0.03913775831460953}\n",
      "{'epoch': 134, 'batch': 1, 'loss': 0.04948924481868744}\n",
      "{'epoch': 135, 'batch': 0, 'loss': 0.03821464627981186}\n",
      "{'epoch': 135, 'batch': 1, 'loss': 0.04829897731542587}\n",
      "{'epoch': 136, 'batch': 0, 'loss': 0.037322238087654114}\n",
      "{'epoch': 136, 'batch': 1, 'loss': 0.0471482127904892}\n",
      "{'epoch': 137, 'batch': 0, 'loss': 0.03645912930369377}\n",
      "{'epoch': 137, 'batch': 1, 'loss': 0.046035394072532654}\n",
      "{'epoch': 138, 'batch': 0, 'loss': 0.035624220967292786}\n",
      "{'epoch': 138, 'batch': 1, 'loss': 0.04495900124311447}\n",
      "{'epoch': 139, 'batch': 0, 'loss': 0.034816544502973557}\n",
      "{'epoch': 139, 'batch': 1, 'loss': 0.04391762986779213}\n",
      "{'epoch': 140, 'batch': 0, 'loss': 0.03403477743268013}\n",
      "{'epoch': 140, 'batch': 1, 'loss': 0.0429098978638649}\n",
      "{'epoch': 141, 'batch': 0, 'loss': 0.033278025686740875}\n",
      "{'epoch': 141, 'batch': 1, 'loss': 0.04193447157740593}\n",
      "{'epoch': 142, 'batch': 0, 'loss': 0.03254517912864685}\n",
      "{'epoch': 142, 'batch': 1, 'loss': 0.04099009558558464}\n",
      "{'epoch': 143, 'batch': 0, 'loss': 0.03183542564511299}\n",
      "{'epoch': 143, 'batch': 1, 'loss': 0.04007558524608612}\n",
      "{'epoch': 144, 'batch': 0, 'loss': 0.031147880479693413}\n",
      "{'epoch': 144, 'batch': 1, 'loss': 0.03918975964188576}\n",
      "{'epoch': 145, 'batch': 0, 'loss': 0.03048151731491089}\n",
      "{'epoch': 145, 'batch': 1, 'loss': 0.038331538438797}\n",
      "{'epoch': 146, 'batch': 0, 'loss': 0.02983567863702774}\n",
      "{'epoch': 146, 'batch': 1, 'loss': 0.03749983385205269}\n",
      "{'epoch': 147, 'batch': 0, 'loss': 0.029209528118371964}\n",
      "{'epoch': 147, 'batch': 1, 'loss': 0.03669365867972374}\n",
      "{'epoch': 148, 'batch': 0, 'loss': 0.02860226109623909}\n",
      "{'epoch': 148, 'batch': 1, 'loss': 0.035912055522203445}\n",
      "{'epoch': 149, 'batch': 0, 'loss': 0.028013233095407486}\n",
      "{'epoch': 149, 'batch': 1, 'loss': 0.0351540707051754}\n",
      "{'epoch': 150, 'batch': 0, 'loss': 0.027441641315817833}\n",
      "{'epoch': 150, 'batch': 1, 'loss': 0.03441882133483887}\n",
      "{'epoch': 151, 'batch': 0, 'loss': 0.026886969804763794}\n",
      "{'epoch': 151, 'batch': 1, 'loss': 0.03370548412203789}\n",
      "{'epoch': 152, 'batch': 0, 'loss': 0.026348549872636795}\n",
      "{'epoch': 152, 'batch': 1, 'loss': 0.03301321715116501}\n",
      "{'epoch': 153, 'batch': 0, 'loss': 0.02582576870918274}\n",
      "{'epoch': 153, 'batch': 1, 'loss': 0.03234126791357994}\n",
      "{'epoch': 154, 'batch': 0, 'loss': 0.025317933410406113}\n",
      "{'epoch': 154, 'batch': 1, 'loss': 0.03168884664773941}\n",
      "{'epoch': 155, 'batch': 0, 'loss': 0.02482471615076065}\n",
      "{'epoch': 155, 'batch': 1, 'loss': 0.031055282801389694}\n",
      "{'epoch': 156, 'batch': 0, 'loss': 0.02434545010328293}\n",
      "{'epoch': 156, 'batch': 1, 'loss': 0.03043987974524498}\n",
      "{'epoch': 157, 'batch': 0, 'loss': 0.023879632353782654}\n",
      "{'epoch': 157, 'batch': 1, 'loss': 0.029841989278793335}\n",
      "{'epoch': 158, 'batch': 0, 'loss': 0.0234268456697464}\n",
      "{'epoch': 158, 'batch': 1, 'loss': 0.029260968789458275}\n",
      "{'epoch': 159, 'batch': 0, 'loss': 0.0229865200817585}\n",
      "{'epoch': 159, 'batch': 1, 'loss': 0.0286962129175663}\n",
      "{'epoch': 160, 'batch': 0, 'loss': 0.022558309137821198}\n",
      "{'epoch': 160, 'batch': 1, 'loss': 0.028147170320153236}\n",
      "{'epoch': 161, 'batch': 0, 'loss': 0.022141829133033752}\n",
      "{'epoch': 161, 'batch': 1, 'loss': 0.02761327102780342}\n",
      "{'epoch': 162, 'batch': 0, 'loss': 0.02173648402094841}\n",
      "{'epoch': 162, 'batch': 1, 'loss': 0.027093976736068726}\n",
      "{'epoch': 163, 'batch': 0, 'loss': 0.02134208381175995}\n",
      "{'epoch': 163, 'batch': 1, 'loss': 0.026588797569274902}\n",
      "{'epoch': 164, 'batch': 0, 'loss': 0.020958153530955315}\n",
      "{'epoch': 164, 'batch': 1, 'loss': 0.026097241789102554}\n",
      "{'epoch': 165, 'batch': 0, 'loss': 0.020584288984537125}\n",
      "{'epoch': 165, 'batch': 1, 'loss': 0.025618843734264374}\n",
      "{'epoch': 166, 'batch': 0, 'loss': 0.020220264792442322}\n",
      "{'epoch': 166, 'batch': 1, 'loss': 0.025153154507279396}\n",
      "{'epoch': 167, 'batch': 0, 'loss': 0.019865646958351135}\n",
      "{'epoch': 167, 'batch': 1, 'loss': 0.024699732661247253}\n",
      "{'epoch': 168, 'batch': 0, 'loss': 0.019520238041877747}\n",
      "{'epoch': 168, 'batch': 1, 'loss': 0.024258160963654518}\n",
      "{'epoch': 169, 'batch': 0, 'loss': 0.01918363943696022}\n",
      "{'epoch': 169, 'batch': 1, 'loss': 0.02382805570960045}\n",
      "{'epoch': 170, 'batch': 0, 'loss': 0.018855594098567963}\n",
      "{'epoch': 170, 'batch': 1, 'loss': 0.02340904250741005}\n",
      "{'epoch': 171, 'batch': 0, 'loss': 0.0185357965528965}\n",
      "{'epoch': 171, 'batch': 1, 'loss': 0.02300073951482773}\n",
      "{'epoch': 172, 'batch': 0, 'loss': 0.0182239580899477}\n",
      "{'epoch': 172, 'batch': 1, 'loss': 0.022602802142500877}\n",
      "{'epoch': 173, 'batch': 0, 'loss': 0.01791989430785179}\n",
      "{'epoch': 173, 'batch': 1, 'loss': 0.022214896976947784}\n",
      "{'epoch': 174, 'batch': 0, 'loss': 0.017623264342546463}\n",
      "{'epoch': 174, 'batch': 1, 'loss': 0.021836694329977036}\n",
      "{'epoch': 175, 'batch': 0, 'loss': 0.017333906143903732}\n",
      "{'epoch': 175, 'batch': 1, 'loss': 0.021467890590429306}\n",
      "{'epoch': 176, 'batch': 0, 'loss': 0.01705157570540905}\n",
      "{'epoch': 176, 'batch': 1, 'loss': 0.021108174696564674}\n",
      "{'epoch': 177, 'batch': 0, 'loss': 0.016775991767644882}\n",
      "{'epoch': 177, 'batch': 1, 'loss': 0.020757246762514114}\n",
      "{'epoch': 178, 'batch': 0, 'loss': 0.016507059335708618}\n",
      "{'epoch': 178, 'batch': 1, 'loss': 0.020414860919117928}\n",
      "{'epoch': 179, 'batch': 0, 'loss': 0.01624440774321556}\n",
      "{'epoch': 179, 'batch': 1, 'loss': 0.020080717280507088}\n",
      "{'epoch': 180, 'batch': 0, 'loss': 0.015987971797585487}\n",
      "{'epoch': 180, 'batch': 1, 'loss': 0.019754573702812195}\n",
      "{'epoch': 181, 'batch': 0, 'loss': 0.01573759689927101}\n",
      "{'epoch': 181, 'batch': 1, 'loss': 0.019436195492744446}\n",
      "{'epoch': 182, 'batch': 0, 'loss': 0.015493005514144897}\n",
      "{'epoch': 182, 'batch': 1, 'loss': 0.0191253200173378}\n",
      "{'epoch': 183, 'batch': 0, 'loss': 0.015253949910402298}\n",
      "{'epoch': 183, 'batch': 1, 'loss': 0.018821731209754944}\n",
      "{'epoch': 184, 'batch': 0, 'loss': 0.015020457096397877}\n",
      "{'epoch': 184, 'batch': 1, 'loss': 0.01852520927786827}\n",
      "{'epoch': 185, 'batch': 0, 'loss': 0.014792191796004772}\n",
      "{'epoch': 185, 'batch': 1, 'loss': 0.018235543742775917}\n",
      "{'epoch': 186, 'batch': 0, 'loss': 0.014569118618965149}\n",
      "{'epoch': 186, 'batch': 1, 'loss': 0.017952511087059975}\n",
      "{'epoch': 187, 'batch': 0, 'loss': 0.014351055026054382}\n",
      "{'epoch': 187, 'batch': 1, 'loss': 0.017675932496786118}\n",
      "{'epoch': 188, 'batch': 0, 'loss': 0.0141378128901124}\n",
      "{'epoch': 188, 'batch': 1, 'loss': 0.01740560308098793}\n",
      "{'epoch': 189, 'batch': 0, 'loss': 0.01392924040555954}\n",
      "{'epoch': 189, 'batch': 1, 'loss': 0.017141351476311684}\n",
      "{'epoch': 190, 'batch': 0, 'loss': 0.013725273311138153}\n",
      "{'epoch': 190, 'batch': 1, 'loss': 0.016882991418242455}\n",
      "{'epoch': 191, 'batch': 0, 'loss': 0.01352572813630104}\n",
      "{'epoch': 191, 'batch': 1, 'loss': 0.01663036271929741}\n",
      "{'epoch': 192, 'batch': 0, 'loss': 0.013330481946468353}\n",
      "{'epoch': 192, 'batch': 1, 'loss': 0.016383282840251923}\n",
      "{'epoch': 193, 'batch': 0, 'loss': 0.01313944160938263}\n",
      "{'epoch': 193, 'batch': 1, 'loss': 0.0161416158080101}\n",
      "{'epoch': 194, 'batch': 0, 'loss': 0.012952450662851334}\n",
      "{'epoch': 194, 'batch': 1, 'loss': 0.015905184671282768}\n",
      "{'epoch': 195, 'batch': 0, 'loss': 0.01276945136487484}\n",
      "{'epoch': 195, 'batch': 1, 'loss': 0.015673859044909477}\n",
      "{'epoch': 196, 'batch': 0, 'loss': 0.012590255588293076}\n",
      "{'epoch': 196, 'batch': 1, 'loss': 0.01544748991727829}\n",
      "{'epoch': 197, 'batch': 0, 'loss': 0.012414835393428802}\n",
      "{'epoch': 197, 'batch': 1, 'loss': 0.015225924551486969}\n",
      "{'epoch': 198, 'batch': 0, 'loss': 0.012243036180734634}\n",
      "{'epoch': 198, 'batch': 1, 'loss': 0.015009048394858837}\n",
      "{'epoch': 199, 'batch': 0, 'loss': 0.012074673548340797}\n",
      "{'epoch': 199, 'batch': 1, 'loss': 0.014796724542975426}\n"
     ]
    }
   ],
   "source": [
    "documents = [\"buku bagus rapih cerdas dan menarik\",\n",
    "             \"rumah rapih cantik dan bersih\",\n",
    "             \"hotel kotor berisik dan bau\",\n",
    "             \"kantin jorok kotor mahal dan panas\"]\n",
    "labels = [[1.], [1.], [0.], [0.]]\n",
    "seq_length = 8\n",
    "dataset = Dataset(seq_length, documents, labels)\n",
    "print(dataset.index_to_word)\n",
    "model = CNNNet(len(dataset.index_to_word), seq_length, 16, 16, 3)\n",
    "train(dataset, model, 2, max_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8647]])\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "  sent = \"hotel dan kantin rapih bersih menarik dan bagus\"\n",
    "  sent = torch.tensor([dataset.to_ids(sent)])\n",
    "  print(model(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
