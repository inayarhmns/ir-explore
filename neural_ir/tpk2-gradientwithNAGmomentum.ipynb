{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nR3qS-ZeYjFo"
   },
   "source": [
    "# Tugas Pemrograman Kecil 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWg-pMzLYmuu"
   },
   "source": [
    "Author: Jaycent Gunawan Ongris (jaycent.gunawan@ui.ac.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kh8vjPCMm1ZJ"
   },
   "source": [
    "Pada tugas ini, Anda akan belajar bagaimana membangun model *neural network from scratch* dengan menggunakan *library* PyTorch. Anda akan bekerja langsung dengan perkalian matriks pada proses *fitting* dan *predicting* menggunakan neural network, tanpa menggunakan abstraksi *layer* pada PyTorch sama sekali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4N_OX78_Ys3h"
   },
   "source": [
    "## Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrqBKSlGYu-H"
   },
   "source": [
    "Pada tutorial ini, Anda akan diberikan sebuah contoh membuat model regresi linear sederhana (*single-layer neural network*) dengan menggunakan PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xm5z6Ox5Y_hf"
   },
   "source": [
    "Fungsi yang akan digunakan sebagai patokan dalam membuat model adalah berikut ini. Koefisien-koefisien dari fungsi berikut akan diprediksi oleh model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-nu6eut4ulx"
   },
   "source": [
    "$$f(a,b,c)=0.5a+0.3b-0.8c+0.5$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:54.106127Z",
     "iopub.status.busy": "2024-10-11T04:54:54.105667Z",
     "iopub.status.idle": "2024-10-11T04:54:54.116535Z",
     "shell.execute_reply": "2024-10-11T04:54:54.115281Z",
     "shell.execute_reply.started": "2024-10-11T04:54:54.106086Z"
    },
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1723735940976,
     "user": {
      "displayName": "Jaycent Gunawan Ongris",
      "userId": "07740026440731769645"
     },
     "user_tz": -420
    },
    "id": "6HdBAz8f6ohZ",
    "outputId": "c9e71dfd-e7a4-4539-8d67-a73fb1cb2ab8",
    "trusted": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'env (Python -1.-1.-1)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/inaya/Documents/LOCAL_TERM7/LOCAL_IR/tpk-ir/env/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# WARNING: DO NOT CHANGE; FOR REPRODUCIBILITY\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:54.120539Z",
     "iopub.status.busy": "2024-10-11T04:54:54.119459Z",
     "iopub.status.idle": "2024-10-11T04:54:54.126672Z",
     "shell.execute_reply": "2024-10-11T04:54:54.125279Z",
     "shell.execute_reply.started": "2024-10-11T04:54:54.120479Z"
    },
    "id": "e87eVQLR4taS",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def f(a, b, c):\n",
    "\n",
    "  return 0.5*a + 0.3*b - 0.8*c + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:54.128866Z",
     "iopub.status.busy": "2024-10-11T04:54:54.128435Z",
     "iopub.status.idle": "2024-10-11T04:54:54.151422Z",
     "shell.execute_reply": "2024-10-11T04:54:54.150040Z",
     "shell.execute_reply.started": "2024-10-11T04:54:54.128822Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1723735941386,
     "user": {
      "displayName": "Jaycent Gunawan Ongris",
      "userId": "07740026440731769645"
     },
     "user_tz": -420
    },
    "id": "xAQEj4we5UWY",
    "outputId": "120ce64f-2c76-4544-cd91-8da1f194f1ee",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4963, 0.7682, 0.0885],\n",
       "        [0.1320, 0.3074, 0.6341],\n",
       "        [0.4901, 0.8964, 0.4556],\n",
       "        [0.6323, 0.3489, 0.4017],\n",
       "        [0.0223, 0.1689, 0.2939],\n",
       "        [0.5185, 0.6977, 0.8000],\n",
       "        [0.1610, 0.2823, 0.6816],\n",
       "        [0.9152, 0.3971, 0.8742],\n",
       "        [0.4194, 0.5529, 0.9527],\n",
       "        [0.0362, 0.1852, 0.3734]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate train dataset\n",
    "\n",
    "X_train = torch.rand(100, 3)\n",
    "\n",
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:54.158568Z",
     "iopub.status.busy": "2024-10-11T04:54:54.158077Z",
     "iopub.status.idle": "2024-10-11T04:54:54.180602Z",
     "shell.execute_reply": "2024-10-11T04:54:54.179275Z",
     "shell.execute_reply.started": "2024-10-11T04:54:54.158523Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1723735941386,
     "user": {
      "displayName": "Jaycent Gunawan Ongris",
      "userId": "07740026440731769645"
     },
     "user_tz": -420
    },
    "id": "lQ1T1GK955JY",
    "outputId": "3b521db3-49a5-4d2e-e84c-760296a6f172",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9078,  0.1510,  0.6495,  0.5994,  0.3267,  0.3286,  0.1199,  0.3774,\n",
       "         0.1134,  0.2749,  0.7914,  0.6547,  0.3045,  0.8341,  0.6913,  0.2312,\n",
       "         0.1279,  0.7540,  0.5048,  0.4088,  0.9104,  0.7084,  0.2962,  0.7710,\n",
       "         0.3745,  1.0983,  0.8019,  1.2352,  0.5873,  0.6802,  0.3812,  0.7045,\n",
       "         0.9683,  0.2276,  0.7343,  0.6911,  0.6726,  0.1941,  0.6444,  0.4383,\n",
       "         0.8023,  0.7115,  0.5043,  0.1777,  0.0431,  0.5130,  0.2671,  0.8301,\n",
       "        -0.0681,  0.7303,  0.2206,  1.1040,  0.6231,  0.4483,  0.2087,  0.2844,\n",
       "        -0.0869,  0.3886,  0.4154,  0.8316,  0.2098,  0.5006,  0.7380,  0.4809,\n",
       "         0.6123,  0.1383,  0.3309,  0.8224,  0.6036,  0.7145,  0.4183,  0.3908,\n",
       "        -0.0972, -0.1094,  0.9412,  0.6305,  0.3895,  0.3667,  0.3787,  0.1421,\n",
       "         0.8238,  0.9645,  0.5512,  0.3256,  0.9004,  0.0783,  0.5103,  0.4162,\n",
       "         0.6524,  0.5884,  0.6894,  0.8265,  0.6673,  0.8456,  0.3523,  0.5393,\n",
       "         0.6798,  0.6402,  0.0747,  0.5098])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute true values\n",
    "\n",
    "y_train = []\n",
    "\n",
    "for inp in X_train:\n",
    "\n",
    "  y = f(inp[0], inp[1], inp[2])\n",
    "\n",
    "  y_train.append(y)\n",
    "\n",
    "y_train = torch.Tensor(y_train)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:54.183787Z",
     "iopub.status.busy": "2024-10-11T04:54:54.183087Z",
     "iopub.status.idle": "2024-10-11T04:54:54.192280Z",
     "shell.execute_reply": "2024-10-11T04:54:54.190909Z",
     "shell.execute_reply.started": "2024-10-11T04:54:54.183711Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:54.194128Z",
     "iopub.status.busy": "2024-10-11T04:54:54.193795Z",
     "iopub.status.idle": "2024-10-11T04:54:54.210365Z",
     "shell.execute_reply": "2024-10-11T04:54:54.208945Z",
     "shell.execute_reply.started": "2024-10-11T04:54:54.194091Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1723735941386,
     "user": {
      "displayName": "Jaycent Gunawan Ongris",
      "userId": "07740026440731769645"
     },
     "user_tz": -420
    },
    "id": "vReLuSb2GhCQ",
    "outputId": "be960999-9c0d-427e-dceb-fb4d804b9e2e",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9078,  0.1510,  0.6495,  0.5994,  0.3267,  0.3286,  0.1199,  0.3774,\n",
       "         0.1134,  0.2749,  0.7914,  0.6547,  0.3045,  0.8341,  0.6913,  0.2312,\n",
       "         0.1279,  0.7540,  0.5048,  0.4088,  0.9104,  0.7084,  0.2962,  0.7710,\n",
       "         0.2403,  1.0983,  0.8019,  0.5982,  0.5873,  0.6802,  0.6152,  0.7045,\n",
       "         0.9683,  0.2276,  0.7343,  0.6911,  0.6726,  0.1941,  0.6444,  0.4383,\n",
       "         0.8023,  0.7115,  0.5043,  0.5898,  0.0431,  0.5130,  0.2671,  0.8301,\n",
       "        -0.0681,  0.7303,  0.2206,  1.1040,  0.6231,  0.4483,  0.2588,  0.2844,\n",
       "        -0.0869,  0.3886,  0.4154,  0.8316,  0.2098,  0.5006,  0.7380,  0.4809,\n",
       "         0.6123,  0.1383,  0.3309,  0.8224,  0.6036,  0.7145,  0.4183,  0.3908,\n",
       "        -0.0972, -0.1094,  0.9412,  0.6305,  0.3895,  0.3667,  0.3787,  0.1421,\n",
       "         0.8238,  0.9645,  0.5512,  0.3256,  0.9004,  0.0783,  0.5103,  0.4162,\n",
       "         0.6524,  0.5884,  0.6894,  0.8265,  0.6673,  0.8456,  0.3523,  0.5393,\n",
       "         0.6798,  0.6402,  0.0747,  0.5098])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative sampling\n",
    "\n",
    "def replace_random_values(data, ratio_to_replace=0.05):\n",
    "\n",
    "  total = data.shape[0]\n",
    "\n",
    "  num_to_replace = int(total * ratio_to_replace)\n",
    "\n",
    "  val_to_replace = torch.rand(num_to_replace, 1)\n",
    "\n",
    "  replaced_index = []\n",
    "\n",
    "  for val in val_to_replace:\n",
    "\n",
    "    idx = random.randint(0, total-1)\n",
    "\n",
    "    while idx in replaced_index:\n",
    "\n",
    "      idx = random.randint(0, total-1)\n",
    "\n",
    "    replaced_index.append(idx)\n",
    "\n",
    "    data[idx] = val\n",
    "\n",
    "  return data\n",
    "\n",
    "\n",
    "\n",
    "y_train = replace_random_values(y_train)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:54.212473Z",
     "iopub.status.busy": "2024-10-11T04:54:54.212044Z",
     "iopub.status.idle": "2024-10-11T04:54:54.225870Z",
     "shell.execute_reply": "2024-10-11T04:54:54.224079Z",
     "shell.execute_reply.started": "2024-10-11T04:54:54.212430Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1723735941386,
     "user": {
      "displayName": "Jaycent Gunawan Ongris",
      "userId": "07740026440731769645"
     },
     "user_tz": -420
    },
    "id": "cgmSTzDDIpoa",
    "outputId": "434b1069-cec0-4d82-da65-bbbb5912d1c7",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4963, 0.7682, 0.0885, 1.0000],\n",
       "        [0.1320, 0.3074, 0.6341, 1.0000],\n",
       "        [0.4901, 0.8964, 0.4556, 1.0000],\n",
       "        [0.6323, 0.3489, 0.4017, 1.0000],\n",
       "        [0.0223, 0.1689, 0.2939, 1.0000],\n",
       "        [0.5185, 0.6977, 0.8000, 1.0000],\n",
       "        [0.1610, 0.2823, 0.6816, 1.0000],\n",
       "        [0.9152, 0.3971, 0.8742, 1.0000],\n",
       "        [0.4194, 0.5529, 0.9527, 1.0000],\n",
       "        [0.0362, 0.1852, 0.3734, 1.0000]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight and biases\n",
    "\n",
    "# squeeze into one matrix only\n",
    "\n",
    "# modify input so that it includes last bias coefficient (1)\n",
    "\n",
    "ones = torch.ones(X_train.shape[0], 1)\n",
    "\n",
    "# dim=1 means the tensor is concatenated as a new column\n",
    "\n",
    "X_train = torch.cat((X_train, ones), dim=1)\n",
    "\n",
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:54.230347Z",
     "iopub.status.busy": "2024-10-11T04:54:54.229896Z",
     "iopub.status.idle": "2024-10-11T04:54:54.241456Z",
     "shell.execute_reply": "2024-10-11T04:54:54.240231Z",
     "shell.execute_reply.started": "2024-10-11T04:54:54.230304Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1723735941386,
     "user": {
      "displayName": "Jaycent Gunawan Ongris",
      "userId": "07740026440731769645"
     },
     "user_tz": -420
    },
    "id": "oC8rKBNAOGOH",
    "outputId": "ba3328f6-d6fc-4b11-c908-d542b335c7ab",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1288, 0.5832, 0.7130, 0.6979], requires_grad=True)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize weights\n",
    "\n",
    "# 4 parameters, include bias\n",
    "\n",
    "# we want to update the W using gradient, hence requires_grad=True\n",
    "\n",
    "W = torch.rand(4, requires_grad=True)\n",
    "\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:54.243856Z",
     "iopub.status.busy": "2024-10-11T04:54:54.243388Z",
     "iopub.status.idle": "2024-10-11T04:54:54.250360Z",
     "shell.execute_reply": "2024-10-11T04:54:54.249077Z",
     "shell.execute_reply.started": "2024-10-11T04:54:54.243814Z"
    },
    "id": "Mu8HEEgmQnuA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# using loss function MSE\n",
    "\n",
    "def mse(inp, target):\n",
    "\n",
    "  diff = inp - target\n",
    "\n",
    "  return torch.sum(torch.pow(diff, 2)) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:54.252378Z",
     "iopub.status.busy": "2024-10-11T04:54:54.251908Z",
     "iopub.status.idle": "2024-10-11T04:54:54.266428Z",
     "shell.execute_reply": "2024-10-11T04:54:54.265028Z",
     "shell.execute_reply.started": "2024-10-11T04:54:54.252335Z"
    },
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1723735941853,
     "user": {
      "displayName": "Jaycent Gunawan Ongris",
      "userId": "07740026440731769645"
     },
     "user_tz": -420
    },
    "id": "AftvX9UTSk8y",
    "outputId": "8239ce21-50b1-427b-8e4c-b0e043efdde2",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2730, 1.3463, 1.6087, 1.2692, 1.0088, 1.7420, 1.3692, 1.6706, 1.7537,\n",
       "        1.0768, 1.4062, 0.8432, 1.7826, 1.2742, 0.8914, 1.7702, 1.5993, 1.6383,\n",
       "        1.3483, 0.9742, 1.3456, 1.5449, 1.7016, 1.1168, 1.9875, 1.2153, 0.9017,\n",
       "        1.3337, 1.3147, 1.2819, 1.8367, 0.9146, 1.2255, 1.8879, 0.9693, 0.9147,\n",
       "        1.3046, 1.5946, 1.1199, 1.5404, 1.2792, 0.9498, 1.1275, 1.3718, 1.6087,\n",
       "        1.3811, 1.9465, 1.7024, 1.4570, 0.9919, 1.0317, 1.2596, 1.1470, 1.2581,\n",
       "        1.0450, 1.4130, 1.6463, 1.7766, 1.4957, 1.3268, 1.6108, 1.6944, 1.0398,\n",
       "        1.9207, 1.1267, 1.3269, 1.3807, 0.9867, 1.4490, 1.6153, 1.3970, 1.4391,\n",
       "        1.4951, 1.6899, 1.1330, 1.1334, 1.3495, 1.8192, 1.4253, 1.3461, 1.5357,\n",
       "        1.2159, 1.2207, 1.2930, 1.1667, 1.2585, 0.9795, 1.8755, 1.2367, 1.7661,\n",
       "        0.9058, 0.9428, 1.2369, 1.1983, 1.6489, 1.4710, 1.1656, 1.5170, 1.4627,\n",
       "        1.3621], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute initial prediction using initialized weights\n",
    "\n",
    "# W.X^T\n",
    "\n",
    "pred = W @ X_train.t()\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:54.269033Z",
     "iopub.status.busy": "2024-10-11T04:54:54.268498Z",
     "iopub.status.idle": "2024-10-11T04:54:54.279000Z",
     "shell.execute_reply": "2024-10-11T04:54:54.277779Z",
     "shell.execute_reply.started": "2024-10-11T04:54:54.268973Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1723735941853,
     "user": {
      "displayName": "Jaycent Gunawan Ongris",
      "userId": "07740026440731769645"
     },
     "user_tz": -420
    },
    "id": "QYdkUWnCTMaR",
    "outputId": "b1b1a2dc-226b-4445-f392-be8ec817286f",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9500, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to minimize the MSE\n",
    "\n",
    "mse(pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yvsoPzlyOUf"
   },
   "source": [
    "Pada kode ini, *batch gradient descent* akan digunakan. Artinya, dalam satu iterasi, semua data akan digunakan untuk *update* parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:54.281368Z",
     "iopub.status.busy": "2024-10-11T04:54:54.280906Z",
     "iopub.status.idle": "2024-10-11T04:54:54.750118Z",
     "shell.execute_reply": "2024-10-11T04:54:54.748724Z",
     "shell.execute_reply.started": "2024-10-11T04:54:54.281324Z"
    },
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1723735942247,
     "user": {
      "displayName": "Jaycent Gunawan Ongris",
      "userId": "07740026440731769645"
     },
     "user_tz": -420
    },
    "id": "pQk4t5QrTJYG",
    "outputId": "6ca49fb4-efe1-46af-e136-53f2b2d53ac8",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: 0.9500129818916321\n",
      "Iteration: 50, Loss: 0.16815663874149323\n",
      "Iteration: 100, Loss: 0.12303473800420761\n",
      "Iteration: 150, Loss: 0.10379736125469208\n",
      "Iteration: 200, Loss: 0.0882379338145256\n",
      "Iteration: 250, Loss: 0.07520835101604462\n",
      "Iteration: 300, Loss: 0.06427919119596481\n",
      "Iteration: 350, Loss: 0.055107682943344116\n",
      "Iteration: 400, Loss: 0.04740781709551811\n",
      "Iteration: 450, Loss: 0.04094042256474495\n",
      "Iteration: 500, Loss: 0.03550555557012558\n",
      "Iteration: 550, Loss: 0.030935952439904213\n",
      "Iteration: 600, Loss: 0.027091719210147858\n",
      "Iteration: 650, Loss: 0.023855777457356453\n",
      "Iteration: 700, Loss: 0.021130142733454704\n",
      "Iteration: 750, Loss: 0.018832797184586525\n",
      "Iteration: 800, Loss: 0.016895070672035217\n",
      "Iteration: 850, Loss: 0.015259427949786186\n",
      "Iteration: 900, Loss: 0.013877689838409424\n",
      "Iteration: 950, Loss: 0.012709439732134342\n",
      "Iteration: 1000, Loss: 0.011720828711986542\n",
      "Iteration: 1050, Loss: 0.010883447714149952\n",
      "Iteration: 1100, Loss: 0.010173458606004715\n",
      "Iteration: 1150, Loss: 0.009570861235260963\n",
      "Iteration: 1200, Loss: 0.009058871306478977\n",
      "Iteration: 1250, Loss: 0.008623367175459862\n",
      "Iteration: 1300, Loss: 0.008252483792603016\n",
      "Iteration: 1350, Loss: 0.007936244830489159\n",
      "Iteration: 1400, Loss: 0.00766625814139843\n",
      "Iteration: 1450, Loss: 0.007435447536408901\n",
      "Iteration: 1500, Loss: 0.007237872574478388\n",
      "Iteration: 1550, Loss: 0.00706849992275238\n",
      "Iteration: 1600, Loss: 0.006923094391822815\n",
      "Iteration: 1650, Loss: 0.006798078306019306\n",
      "Iteration: 1700, Loss: 0.006690428126603365\n",
      "Iteration: 1750, Loss: 0.00659759109839797\n",
      "Iteration: 1800, Loss: 0.006517403293401003\n",
      "Iteration: 1850, Loss: 0.00644802488386631\n",
      "Iteration: 1900, Loss: 0.0063879042863845825\n",
      "Iteration: 1950, Loss: 0.006335722282528877\n"
     ]
    }
   ],
   "source": [
    "# use batch gradient descent\n",
    "\n",
    "NUM_EPOCHS = 2000\n",
    "\n",
    "LR = 1e-2\n",
    "\n",
    "\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "\n",
    "  # make predictions\n",
    "\n",
    "  pred_i = W @ X_train.t()\n",
    "\n",
    "  loss = mse(pred_i, y_train)\n",
    "\n",
    "  loss_history.append(loss)\n",
    "\n",
    "  if i % 50 == 0:\n",
    "\n",
    "    print(f'Iteration: {i}, Loss: {loss}')\n",
    "\n",
    "  # compute the gradient of loss w.r.t W\n",
    "\n",
    "  loss.backward()\n",
    "\n",
    "  # the gradient value can be accessed using W.grad\n",
    "\n",
    "\n",
    "\n",
    "  # we don't want to compute gradients in this context manager\n",
    "\n",
    "  # operations within this context manager will not be tracked for autodiff\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    # update parameters\n",
    "\n",
    "    W -= LR * W.grad\n",
    "\n",
    "    # reset gradients\n",
    "\n",
    "    W.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:54.755196Z",
     "iopub.status.busy": "2024-10-11T04:54:54.754754Z",
     "iopub.status.idle": "2024-10-11T04:54:54.764762Z",
     "shell.execute_reply": "2024-10-11T04:54:54.763153Z",
     "shell.execute_reply.started": "2024-10-11T04:54:54.755128Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1723735942247,
     "user": {
      "displayName": "Jaycent Gunawan Ongris",
      "userId": "07740026440731769645"
     },
     "user_tz": -420
    },
    "id": "O98dtrlbV_nw",
    "outputId": "91748112-a4ab-4582-d074-2e5f14521e01",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4654,  0.2576, -0.6916,  0.4837], requires_grad=True)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameter result\n",
    "\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:54.766933Z",
     "iopub.status.busy": "2024-10-11T04:54:54.766511Z",
     "iopub.status.idle": "2024-10-11T04:54:54.795599Z",
     "shell.execute_reply": "2024-10-11T04:54:54.794208Z",
     "shell.execute_reply.started": "2024-10-11T04:54:54.766887Z"
    },
    "id": "lD8UD0KPcJlU",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# convert loss_history\n",
    "\n",
    "loss_history = [loss.detach().numpy().item() for loss in loss_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:54.802224Z",
     "iopub.status.busy": "2024-10-11T04:54:54.801789Z",
     "iopub.status.idle": "2024-10-11T04:54:55.094218Z",
     "shell.execute_reply": "2024-10-11T04:54:55.092937Z",
     "shell.execute_reply.started": "2024-10-11T04:54:54.802153Z"
    },
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1723735942874,
     "user": {
      "displayName": "Jaycent Gunawan Ongris",
      "userId": "07740026440731769645"
     },
     "user_tz": -420
    },
    "id": "uVU5eU6JYL5O",
    "outputId": "a61fd2b4-a15f-4478-e111-9c4cb18e9fdc",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(loss_history)\n",
    "\n",
    "plt.title(\"MSE Loss History\")\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1KgZZ43yfiK"
   },
   "source": [
    "Pada grafik tersebut, dapat dilihat bahwa *loss* menurun pada tiap *epoch*-nya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VF4ij4rbchzp"
   },
   "source": [
    "## Tugas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8g6e34QcjTx"
   },
   "source": [
    "Tugas Anda adalah membuat model klasifikasi menggunakan *multi-layer dense neural network* untuk menyelesaikan permasalahan klasifikasi pada dataset Iris. Spesifikasi model yang diinginkan adalah sebagai berikut.\n",
    "\n",
    "\n",
    "\n",
    "*   Anda tidak diperkenankan menggunakan *layer built-in* PyTorch; semuanya harus menggunakan ***matrix multiplication*** untuk perhitungan *forward pass*.\n",
    "\n",
    "*   Ukuran *hidden layer* (termasuk *input layer* dan *output layer*) adalah 4, 10, 20, 10, 3.\n",
    "\n",
    "*   *Loss function* yang digunakan adalah Categorical Cross Entropy (CCE).\n",
    "\n",
    "*   Gunakan *activation function* ReLU setelah tiap *layer* kecuali *layer* terakhir.\n",
    "\n",
    "*   Ingat untuk menggunakan softmax setelah *layer* terakhir.\n",
    "\n",
    "*   Implementasi *optimizer* menggunakan *mini-batch gradient descent*.\n",
    "\n",
    "*   Implementasi Nesterov Accelerated Gradient (NAG) dengan koefisien momentum 0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqwKj1bwMq5t"
   },
   "source": [
    "*Update* parameter pada Nesterov Accelerated Gradient (NAG) dapat dirumuskan:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ttNf_IvM091"
   },
   "source": [
    "$$v_t = \\gamma v_{t-1}-\\alpha \\nabla_{\\theta}J(\\theta_{t-1} + \\gamma v_{t-1})$$\n",
    "\n",
    "$$\\theta_{t}=\\theta_{t-1} + v_{t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vr79iM8-NiXc"
   },
   "source": [
    "Dengan penjelasan sebagai berikut.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*   $v_t$ adalah *velocity* pada iterasi ke-t.\n",
    "\n",
    "*   $\\gamma$ adalah koefisien momentum.\n",
    "\n",
    "*   $\\alpha$ adalah *learning rate*.\n",
    "\n",
    "*   $J$ adalah *loss function*, dalam hal ini adalah CCE.\n",
    "\n",
    "*   $\\theta_{t}$ adalah parameter pada iterasi ke-t.\n",
    "\n",
    "\n",
    "\n",
    "Inisialisasi $v$ dengan nilai $0$, dengan ukuran sama dengan $\\theta$. Perhatikan bahwa matriks parameter $\\theta$ di tiap *layer* harus di-*update*.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJgWX74hSWkc"
   },
   "source": [
    "Jika Anda tertarik untuk mengetahui lebih lanjut terkait NAG, Anda dapat mengunjungi [URL](https://mitliagkas.github.io/ift6085-2019/ift-6085-lecture-6-notes.pdf) ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:55.097789Z",
     "iopub.status.busy": "2024-10-11T04:54:55.097327Z",
     "iopub.status.idle": "2024-10-11T04:54:55.110964Z",
     "shell.execute_reply": "2024-10-11T04:54:55.109459Z",
     "shell.execute_reply.started": "2024-10-11T04:54:55.097745Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1723735942875,
     "user": {
      "displayName": "Jaycent Gunawan Ongris",
      "userId": "07740026440731769645"
     },
     "user_tz": -420
    },
    "id": "Qaj1e0Pxc3Eb",
    "outputId": "0bc06e87-c835-4d21-c752-d600ead8b709",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (120, 4)\n",
      "Testing set size: (30, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "\n",
    "\n",
    "X = iris.data\n",
    "\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "\n",
    "# train-test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "\n",
    "print(\"Testing set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKjucNLPXjlu"
   },
   "source": [
    "Lengkapilah potongan kode berikut pada bagian yang ditandai dengan `# TODO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:55.113852Z",
     "iopub.status.busy": "2024-10-11T04:54:55.113351Z",
     "iopub.status.idle": "2024-10-11T04:54:55.142445Z",
     "shell.execute_reply": "2024-10-11T04:54:55.140989Z",
     "shell.execute_reply.started": "2024-10-11T04:54:55.113805Z"
    },
    "id": "YXWcqda6dhV_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MLPClassifier:\n",
    "\n",
    "  def __init__(self, hidden_size_list, eps=1e-9, epochs=2000, lr=1e-4, batch_size=None, momentum=0.9):\n",
    "\n",
    "    # WARNING: DO NOT CHANGE; FOR REPRODUCIBILITY\n",
    "\n",
    "    torch.manual_seed(15)\n",
    "\n",
    "    # size of hidden layers, including input and output\n",
    "\n",
    "    self.hidden_size_list = hidden_size_list\n",
    "\n",
    "    # list of trainable parameters (for each layer)\n",
    "\n",
    "    self.weights = []\n",
    "\n",
    "    # small constant to prevent division by zero in computing CCE\n",
    "\n",
    "    self.eps = eps\n",
    "\n",
    "    # number of iterations\n",
    "\n",
    "    self.epochs = epochs\n",
    "\n",
    "    # learning rate\n",
    "\n",
    "    self.lr = lr\n",
    "\n",
    "    # if batch_size = None, then use batch gradient descent\n",
    "\n",
    "    self.batch_size = batch_size\n",
    "\n",
    "    # momentum coefficient\n",
    "\n",
    "    self.momentum = momentum\n",
    "\n",
    "    # list of NAG velocities (for each layer)\n",
    "\n",
    "    self.velocities = []\n",
    "\n",
    "\n",
    "\n",
    "  def _init_weights(self):\n",
    "\n",
    "    # modify first hidden layer to include bias\n",
    "\n",
    "    hids = self.hidden_size_list\n",
    "\n",
    "    hids[0] += 1\n",
    "\n",
    "    for i in range(len(hids)-1):\n",
    "\n",
    "      row_size = hids[i]\n",
    "\n",
    "      col_size = hids[i+1]\n",
    "\n",
    "      # initialize using Glorot initialization\n",
    "\n",
    "      # read this for more info: https://pytorch.org/docs/stable/_modules/torch/nn/init.html#xavier_uniform_\n",
    "\n",
    "      init = torch.nn.init.xavier_uniform_(torch.empty(row_size, col_size))\n",
    "\n",
    "      self.weights.append(torch.nn.Parameter(init, requires_grad=True))\n",
    "\n",
    "      self.velocities.append(torch.zeros_like(init))\n",
    "\n",
    "\n",
    "\n",
    "  def fit(self, X_train, y_train):\n",
    "\n",
    "    if X_train.shape[1] != self.hidden_size_list[0]:\n",
    "\n",
    "      raise RuntimeError('The size of the first layer and the number of features mismatch.')\n",
    "\n",
    "    if len(set(y_train)) != self.hidden_size_list[-1]:\n",
    "\n",
    "      raise RuntimeError('The size of the last layer and the number of output classes mismatch.')\n",
    "\n",
    "    if self.batch_size == None:\n",
    "\n",
    "      # batch GD\n",
    "\n",
    "      self.batch_size = X_train.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "    # weights initialization and tensor conversion\n",
    "\n",
    "    self._init_weights()\n",
    "\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "    # modify X_train to include bias using vector of ones\n",
    "\n",
    "    ones = torch.ones(X_train.shape[0], 1)\n",
    "\n",
    "    X_train = torch.cat((X_train, ones), dim=1)\n",
    "\n",
    "\n",
    "\n",
    "    # convert to one hot encoding\n",
    "\n",
    "    y_train = torch.nn.functional.one_hot(y_train, num_classes=self.hidden_size_list[-1])\n",
    "\n",
    "\n",
    "\n",
    "    # training\n",
    "\n",
    "    for i in range(self.epochs):\n",
    "\n",
    "      # shuffle data (must be consistent between X and y)\n",
    "\n",
    "      # for mini-batch or stochastic gradient descent\n",
    "\n",
    "      # not affecting batch gradient descent\n",
    "\n",
    "      indices = torch.randperm(X_train.shape[0])\n",
    "\n",
    "      X_train = X_train[indices]\n",
    "\n",
    "      y_train = y_train[indices]\n",
    "\n",
    "\n",
    "\n",
    "      # TODO: Lakukan iterasi mini-batch gradient descent\n",
    "\n",
    "      for j in range(0, X_train.shape[0], self.batch_size):\n",
    "        X_batch = X_train[j:j+self.batch_size]\n",
    "        y_batch = y_train[j:j+self.batch_size]\n",
    "\n",
    "        # Forward pass with lookahead weights\n",
    "        lookahead_weights = [w + self.momentum * v for w, v in zip(self.weights, self.velocities)]\n",
    "        y_pred = self._forward(X_batch)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = self._cceloss(y_pred, y_batch)\n",
    "\n",
    "        # Backpropagation (Manual gradients computation)\n",
    "        grads = torch.autograd.grad(loss, lookahead_weights, retain_graph=True)\n",
    "\n",
    "        # Update velocities and weights using NAG\n",
    "        for l in range(len(self.weights)):\n",
    "            self.velocities[l] = self.momentum * self.velocities[l] - self.lr * grads[l]\n",
    "            self.weights[l] = self.weights[l] + self.velocities[l]\n",
    "    \n",
    "        # if i % 100 == 0:\n",
    "        #         print(f'Epoch {i}, Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "      # progress\n",
    "\n",
    "      if i % 100 == 0:\n",
    "\n",
    "        print(f'Iteration: {i}, Loss: {loss}')\n",
    "\n",
    "\n",
    "\n",
    "  def _softmax(self, x):\n",
    "\n",
    "    # TODO: Implementasi softmax\n",
    "\n",
    "    exps = torch.exp(x - torch.max(x))  # Subtract max for numerical stability\n",
    "    return exps / torch.sum(exps, dim=1, keepdim=True)\n",
    "\n",
    "\n",
    "\n",
    "  def _cceloss(self, y_pred, y_true):\n",
    "\n",
    "    # TODO: Implementasi CCE loss\n",
    "\n",
    "    y_pred = torch.clamp(y_pred, min=self.eps, max=1.0 - self.eps)  # Prevent log(0)\n",
    "    return -torch.sum(y_true * torch.log(y_pred)) / y_pred.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "  def _forward(self, X):\n",
    "\n",
    "    # TODO: Lakukan forward propagation\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "  def _relu(self, X):\n",
    "\n",
    "    # TODO: Implementasi ReLU\n",
    "\n",
    "    return torch.max(torch.tensor(0.0), X)\n",
    "\n",
    "\n",
    "\n",
    "  def predict(self, X_test):\n",
    "\n",
    "    # TODO: Implementasi fungsi untuk prediksi dari suatu dataset\n",
    "\n",
    "    # Output dari fungsi ini adalah class yang diprediksi, yakni 0, 1, atau 2\n",
    "\n",
    "    # Anda dapat menggunakan fungsi torch.argmax()\n",
    "\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    # Tambahkan bias pada input test\n",
    "    ones = torch.ones(X_test.shape[0], 1)\n",
    "    X_test = torch.cat((X_test, ones), dim=1)\n",
    "    # Lakukan forward propagation\n",
    "    y_pred = self._forward(X_test)\n",
    "    # Prediksi class (0, 1, atau 2)\n",
    "    return torch.argmax(y_pred, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisi koreksi inaya 4-11\n",
    "# grad descent with momentum\n",
    "# Hyperparameters\n",
    "NUM_EPOCHS = 2000\n",
    "LR = 1e-2\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "# Initialize velocity\n",
    "velocity = torch.zeros_like(W)\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "    # Nesterov look-ahead step: compute the gradient at the look-ahead position\n",
    "    with torch.no_grad():\n",
    "        W_lookahead = W - MOMENTUM * velocity\n",
    "\n",
    "    # Make predictions using the look-ahead weights\n",
    "    pred_i = W_lookahead @ X_train.t()\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = mse(pred_i, y_train)\n",
    "    loss_history.append(loss.item())\n",
    "\n",
    "    # Print progress every 50 iterations\n",
    "    if i % 50 == 0:\n",
    "        print(f'Iteration: {i}, Loss: {loss.item()}')\n",
    "\n",
    "    # Compute gradients of the loss w.r.t. W (using look-ahead weights)\n",
    "    loss.backward()\n",
    "\n",
    "    # Update velocity and apply it to weights with learning rate and momentum\n",
    "    with torch.no_grad():\n",
    "        # Compute the velocity update\n",
    "        velocity = MOMENTUM * velocity + LR * W.grad\n",
    "        \n",
    "        # Update the weights using NAG\n",
    "        W -= velocity\n",
    "\n",
    "        # Zero out the gradients for the next iteration\n",
    "        W.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*koreksi inaya 4-11*\n",
    "\n",
    "\n",
    "Velocity represents the ball's speed and direction. As you push it, the ball starts to roll and gains speed in a particular direction, which it retains over time. If you encounter a small hill (change in gradient), the ball doesn't immediately stop but continues in the general direction it's been pushed.\n",
    "\n",
    "\n",
    "Momentum is a factor that determines how much the ball's current speed should depend on its past speed. High momentum (close to 1) means the ball keeps a lot of its past speed, helping it roll over small obstacles. Low momentum (close to 0) means it mostly relies on the current push (gradient) without much influence from the past.\n",
    "\n",
    "In standard momentum-based gradient descent, the gradient is calculated at the current position of the parameters, and then the parameters are updated by moving in the direction of the accumulated momentum (velocity).\n",
    "\n",
    "\n",
    "In NAG, we first “look ahead” in the direction of the accumulated momentum (like taking a small predictive step) before calculating the gradient. This means that the gradient is computed based on an anticipated position, not the current position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sjv6wR5yX7c0"
   },
   "source": [
    "Setelah melengkapi kode di atas, jalankan eksperimen sesuai dengan kondisi-kondisi yang diberikan berikut untuk membandingkan performa batch, mini-batch, dan stochastic gradient descent, dengan dan tanpa Nesterov's momentum.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*   Batch gradient descent tanpa momentum\n",
    "\n",
    "*   Batch gradient descent dengan momentum ($\\gamma=0.9$)\n",
    "\n",
    "*   Mini-batch gradient descent (batch size = 12) tanpa momentum\n",
    "\n",
    "*   Mini-batch gradient descent (batch size = 12) dengan momentum ($\\gamma=0.9$)\n",
    "\n",
    "*   Stochastic gradient descent tanpa momentum\n",
    "\n",
    "*   Stochastic gradient descent dengan momentum ($\\gamma=0.9$)\n",
    "\n",
    "\n",
    "\n",
    "Semua konfigurasi eksperimen yang lain (*epochs*, *learning rate*, dll.) bebas ditentukan oleh Anda sendiri. Akan tetapi, pastikan bahwa semua eksperimen menggunakan konfigurasi yang sama. Sebagai contoh, jika Anda menentukan jumlah iterasi yang digunakan adalah 100, maka pastikan semua eksperimen tersebut menggunakan 100 iterasi.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T04:54:55.144363Z",
     "iopub.status.busy": "2024-10-11T04:54:55.143932Z",
     "iopub.status.idle": "2024-10-11T04:54:55.303009Z",
     "shell.execute_reply": "2024-10-11T04:54:55.301333Z",
     "shell.execute_reply.started": "2024-10-11T04:54:55.144320Z"
    },
    "id": "sFVBqUK0ZvHS",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with batch_size=120, momentum=0.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (120x5 and 4x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# 1. Batch Gradient Descent tanpa momentum\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m results[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# 2. Batch Gradient Descent dengan momentum\u001b[39;00m\n\u001b[1;32m     53\u001b[0m results[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m run_experiment(batch_size\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n",
      "Cell \u001b[0;32mIn[135], line 35\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(batch_size, momentum)\u001b[0m\n\u001b[1;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m MLPClassifier(hidden_size_list\u001b[38;5;241m=\u001b[39mhidden_size_list, \n\u001b[1;32m     29\u001b[0m                       epochs\u001b[38;5;241m=\u001b[39mepochs, \n\u001b[1;32m     30\u001b[0m                       lr\u001b[38;5;241m=\u001b[39mlearning_rate, \n\u001b[1;32m     31\u001b[0m                       batch_size\u001b[38;5;241m=\u001b[39mbatch_size, \n\u001b[1;32m     32\u001b[0m                       momentum\u001b[38;5;241m=\u001b[39mmomentum)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[1;32m     38\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Cell \u001b[0;32mIn[134], line 54\u001b[0m, in \u001b[0;36mMLPClassifier.fit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Forward pass with lookahead weights\u001b[39;00m\n\u001b[1;32m     53\u001b[0m lookahead_weights \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;241m*\u001b[39m v \u001b[38;5;28;01mfor\u001b[39;00m w, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvelocities)]\n\u001b[0;32m---> 54\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m     57\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cceloss(y_pred, y_batch)\n",
      "Cell \u001b[0;32mIn[134], line 81\u001b[0m, in \u001b[0;36mMLPClassifier._forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     79\u001b[0m out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 81\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_relu(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     82\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_softmax(torch\u001b[38;5;241m.\u001b[39mmatmul(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (120x5 and 4x10)"
     ]
    }
   ],
   "source": [
    "# TODO: Eksperimen dengan menggunakan 6 kondisi di atas\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load and preprocess the Iris dataset\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define hyperparameters\n",
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "batch_size = None  # Will be set dynamically\n",
    "momentum = 0.0  # Will be set dynamically for momentum cases\n",
    "\n",
    "# Define the hidden layer sizes\n",
    "hidden_size_list = [4, 10, 20, 10, 3]\n",
    "\n",
    "# Define a function to run an experiment\n",
    "def run_experiment(batch_size, momentum):\n",
    "    print(f\"Running experiment with batch_size={batch_size}, momentum={momentum}\")\n",
    "\n",
    "    # Initialize MLPClassifier model\n",
    "    model = MLPClassifier(hidden_size_list=hidden_size_list, \n",
    "                          epochs=epochs, \n",
    "                          lr=learning_rate, \n",
    "                          batch_size=batch_size, \n",
    "                          momentum=momentum)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred\n",
    "    # # Calculate accuracy\n",
    "    # accuracy = accuracy_score(y_test, y_pred.numpy())  # Convert torch tensor to numpy array for accuracy calculation\n",
    "    \n",
    "    # print(f\"Accuracy: {accuracy}\")\n",
    "    # return accuracy\n",
    "\n",
    "# Experiments\n",
    "results = {}\n",
    "\n",
    "# 1. Batch Gradient Descent tanpa momentum\n",
    "results[1] = run_experiment(batch_size=X_train.shape[0], momentum=0.0)\n",
    "\n",
    "# 2. Batch Gradient Descent dengan momentum\n",
    "results[2] = run_experiment(batch_size=X_train.shape[0], momentum=0.9)\n",
    "\n",
    "# 3. Mini-batch Gradient Descent (batch size = 12) tanpa momentum\n",
    "results[3] = run_experiment(batch_size=12, momentum=0.0)\n",
    "\n",
    "# 4. Mini-batch Gradient Descent (batch size = 12) dengan momentum\n",
    "results[4] = run_experiment(batch_size=12, momentum=0.9)\n",
    "\n",
    "# 5. Stochastic Gradient Descent (batch size = 1) tanpa momentum\n",
    "results[5] = run_experiment(batch_size=1, momentum=0.0)\n",
    "\n",
    "# 6. Stochastic Gradient Descent (batch size = 1) dengan momentum\n",
    "results[6] = run_experiment(batch_size=1, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MMCammtA0Op"
   },
   "source": [
    "Evaluasi hasil klasifikasi keenam eksperimen tersebut dengan metrik akurasi. Gunakan data *test* sesuai yang telah di-*split* sebelumnya (`X_test` dengan ground truth `y_test`). Berikan sedikit penjelasan terkait hasil klasifikasi tersebut, apakah sesuai ekspektasi Anda dengan mempertimbangkan *loss*-nya? Anda dapat menggunakan `accuracy_score` untuk menghitung skor akurasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-11T04:54:55.303909Z",
     "iopub.status.idle": "2024-10-11T04:54:55.304347Z",
     "shell.execute_reply": "2024-10-11T04:54:55.304139Z",
     "shell.execute_reply.started": "2024-10-11T04:54:55.304117Z"
    },
    "id": "07S2C23UBuDb",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# TODO: Evaluasi akurasi\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def calc_accuracy(y_test=y_test, y_pred, key):\n",
    "    accuracy = accuracy_score(y_test, y_pred.numpy())  # Convert torch tensor to numpy array for accuracy calculation\n",
    "    \n",
    "    print(f\"Accuracy {key}: {accuracy}\")\n",
    "    return accuracy\n",
    "\n",
    "for i,j in results.items():\n",
    "    calc_accuracy(j, i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ByeWalkaYrK"
   },
   "source": [
    "Jelaskan apa yang bisa Anda dapatkan dari percobaan tersebut! Tentukan metode apa yang menurut Anda memiliki performa yang paling baik, jelaskan alasan Anda memilih metode tersebut, dan jelaskan mengapa metode tersebut memberikan performa yang paling baik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Va_RL7cavNr"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "> TODO: Jawab pertanyaan tersebut\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMEPUNGmchn91fODwpOxdvK",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
